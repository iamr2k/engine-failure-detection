<!DOCTYPE HTML>

<html>
	<head>
		<title>Engine Sound</title>
		<meta charset="utf-8" />
                <meta name="theme-color" content="#F8F9F9" />
                <link rel="shortcut icon" href="{{ url_for('static', filename='favicon.png') }}">
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="{{ url_for('static', filename='main.css') }}">
		<link rel="stylesheet" href="main.css">
		<link href="https://fonts.googleapis.com/css2?family=Open+Sans:wght@300&display=swap" rel="stylesheet">
		<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
	</head>
	<body class="is-preload">

		<!-- Header -->
		
		<br><br>
		<br><br><br>
			<header id="header" >
				<h1>Artificial Intelligence <br> to analyse vehicle sound</h1>
				<p>This is a beta experiment to check I.C engine's R.P.M by analysing engine sound</p>
			</header>
			<main><br>
			<button type="button" class="buttonload" onclick="init()" style="display: flex;
			justify-content: center; margin-left:26%;" > Start</button>
			  </main>
			<br><br><br>
			<div id="label-container"></div>
			<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.3.1/dist/tf.min.js"></script>
			<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/speech-commands@0.4.0/dist/speech-commands.min.js"></script>
			
			
			
<script>
	class AudioVisualizer {
		constructor(audioContext, processFrame, processError) {
		  this.audioContext = audioContext;
		  this.processFrame = processFrame;
		  this.connectStream = this.connectStream.bind(this);
		  navigator.mediaDevices.
		  getUserMedia({ audio: true, video: false }).
		  then(this.connectStream).
		  catch(error => {
			if (processError) {
			  processError(error);
			}
		  });
		}
	  
		connectStream(stream) {
		  this.analyser = this.audioContext.createAnalyser();
		  const source = this.audioContext.createMediaStreamSource(stream);
		  source.connect(this.analyser);
		  this.analyser.smoothingTimeConstant = 0.5;
		  this.analyser.fftSize = 32;
	  
		  this.initRenderLoop(this.analyser);
		}
	  
		initRenderLoop() {
		  const frequencyData = new Uint8Array(this.analyser.frequencyBinCount);
		  const processFrame = this.processFrame || (() => {});
	  
		  const renderFrame = () => {
			this.analyser.getByteFrequencyData(frequencyData);
			processFrame(frequencyData);
	  
			requestAnimationFrame(renderFrame);
		  };
		  requestAnimationFrame(renderFrame);
		}}
	  
	  
	  const visualMainElement = document.querySelector("main");
	  const visualValueCount = 16;
	  let visualElements;
	  const createDOMElements = () => {
		let i;
		for (i = 0; i < visualValueCount; ++i) {
		  const elm = document.createElement("div");
		  visualMainElement.appendChild(elm);
		}
	  
		visualElements = document.querySelectorAll("main div");
	  };
	  createDOMElements();
	  


				// more documentation available at
				// https://github.com/tensorflow/tfjs-models/tree/master/speech-commands
			
				// the link to your model provided by Teachable Machine export panel
				const URL = "https://teachablemachine.withgoogle.com/models/JYXi93bh4/";
			
				async function createModel() {
					const checkpointURL = URL + "model.json"; // model topology
					const metadataURL = URL + "metadata.json"; // model metadata
			
					const recognizer = speechCommands.create(
						"BROWSER_FFT", // fourier transform type, not useful to change
						undefined, // speech commands vocabulary feature, not useful for your models
						checkpointURL,
						metadataURL);
			
					// check that model and metadata are loaded via HTTPS requests.
					await recognizer.ensureModelLoaded();
			
					return recognizer;
				}
			
				async function init() {
					const recognizer = await createModel();
					const classLabels = recognizer.wordLabels(); // get class labels
					const labelContainer = document.getElementById("label-container");
						// Creating initial DOM elements
						const audioContext = new AudioContext();
						const initDOM = () => {
						  visualMainElement.innerHTML = "";
						  createDOMElements();
						};
						initDOM();
					  
						// Swapping values around for a better visual effect
						const dataMap = {
						  0: 15,
						  1: 10,
						  2: 8,
						  3: 9,
						  4: 6,
						  5: 5,
						  6: 2,
						  7: 1,
						  8: 0,
						  9: 4,
						  10: 3,
						  11: 7,
						  12: 11,
						  13: 12,
						  14: 13,
						  15: 14 };
					  
						const processFrame = data => {
						  const values = Object.values(data);
						  let i;
						  for (i = 0; i < visualValueCount; ++i) {
							const value = values[dataMap[i]] / 255;
							const elmStyles = visualElements[i].style;
							elmStyles.transform = `scaleY( ${value} )`;
							elmStyles.opacity = Math.max(0.25, value);
						  }
						};
					  
						const processError = () => {
						  visualMainElement.classList.add("error");
						  visualMainElement.innerText =
						  "Please allow access to your microphone in order to see this demo.\nNothing bad is going to happen... hopefully :P";
						};
					  
						const a = new AudioVisualizer(audioContext, processFrame, processError);
					for (let i = 0; i < classLabels.length; i++) {
						labelContainer.appendChild(document.createElement("div"));
					}
			
					// listen() takes two arguments:
					// 1. A callback function that is invoked anytime a word is recognized.
					// 2. A configuration object with adjustable fields
					recognizer.listen(result => {
						const scores = result.scores; // probability of prediction for each class
						// render the probability scores per class
						for (let i = 0; i < 1; i++) {
							const classPrediction = classLabels[i] + ": " + result.scores[i].toFixed(2);
							
							if (result.scores[2] > 0.9) {
								labelContainer.childNodes[i].innerHTML = "<header id='header'>BACKGROUND NOICES</header id='header'>";
							}
							else if (result.scores[0] > 0.9) {
								labelContainer.childNodes[i].innerHTML = "<header id='header'>1000 - RPM</header id='header'>";
							}
							else if (result.scores[1] > 0.9) {
								labelContainer.childNodes[i].innerHTML = "<header id='header'>2000 - RPM</header id='header'>";
							}
							else {
								labelContainer.childNodes[i].innerHTML = "<header id='header'>    Analysing    </header id='header'>";
							}
							
							
						}
					}, {
						includeSpectrogram: true, // in case listen should return result.spectrogram
						probabilityThreshold: 0.6, // probability threshold for including a detected word in the result
						invokeCallbackOnNoiseAndUnknown: true,
						overlapFactor: 0 // probably want between 0.5 and 0.75. More info in README
					});
			
					// Stop the recognition in 15 seconds.
					//setTimeout(() => recognizer.stopListening(), 35000);
				}
			</script>

		


			






		<!-- Scripts -->
			<script src="{{ url_for('static', filename='main.js') }}"></script>
			<script src="main.js"></script>

	</body>
</html>
